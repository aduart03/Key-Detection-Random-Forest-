# -*- coding: utf-8 -*-
"""Random Forest Model - ML Final.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1mgNOOSAsz7NzNXTcabYUnqBmTEzg6Dg5
"""

# Data set has to be downloaded before running this script!
# On this notebbok the dataset is located in the root derectory as a refernce to another google drive.
# Dataset will also be provided per team:
# - Dataset should be of size 2.1 GB or more - "fmak_wav-20251212T081948Z-3-002" or "FMAK_data"
#from google.colab import drive
import os
import pandas as pd
import numpy as np

from glob import glob
import subprocess
import soundfile as sf

import librosa
from tqdm import tqdm

#!pip install imbalanced-learn

#!ls /content/drive/MyDrive/Colab\ Notebooks/Random\ Forest\ Model\ -\ ML\ Final

# Step 1: Open the dataset
#from google.colab import drive
#drive.mount('/content/drive')

#DRIVE_ROOT = "/content/drive/MyDrive/Colab Notebooks/Random Forest Model - ML Final"
REPO_ROOT = os.path.dirname(os.path.abspath(__file__))
DATA_ROOT = os.path.join(REPO_ROOT, "audio_features")
AVAILABLE_CSV = os.path.join(DATA_ROOT, "available_balanced.csv")
if not os.path.exists(AVAILABLE_CSV):
    raise FileNotFoundError(
        f"CSV not found: {AVAILABLE_CSV}\n"
        f"Contents of {DATA_ROOT}: {os.listdir(DATA_ROOT)[:50]}"
    )


#wav_files = os.path.join(DRIVE_ROOT,"fmak_wav")

df = pd.read_csv(AVAILABLE_CSV)
df.head()

# Step 2: Encode the key labels

# encoding keys as integers
tonics = ["C","C#/Db","D","D#/Eb","E","F","F#Gb","G","G#/Ab","A", "A#/Bb", "B"]
modes = ["major", "minor"]

Mkey_labels = {}  #Hashmap or Dictionary

index = 0
for mode in modes:
  for key in tonics:
    Mkey_labels[key+" "+mode] = index
    index += 1

'''
Encoding global key values in dataframe into integers, based on the Mkey_labels dictionary
The model is intended to use a label such as "C#Db" when classifying an enharmonic key.
However, the dataset only lists one of the two keys in the enharmonics pair; this needs to be accounted for
'''

# Creating a normalization dictionary
canon = {
    "C":"C",
    "C#":"C#/Db",
    "Db": "C#/Db",
    "D": "D",
    "D#": "D#/Eb",
    "Eb#": "D#/Eb",
    "E": "E",
    "F": "F",
    "F#": "F#Gb",
    "Gb": "Gb",
    "G": "G",
    "G#": "G#/Ab",
    "Ab": "G#/Ab",
    "A": "A",
    "A#": "A#/Bb",
    "Bb": "A#/Bb",
    "B": "B"
}

'''
(normalization) converting keys to cannonical labels
Example, if key = Bb major, then normalize_key ("Bb major") will
convert "Bb" to "A#/Bb" and return "A#/Bb major"
'''

def normalize_key(s):
  tonic, mode = s.split()
  tonic = canon[tonic]
  mode = mode.lower()
  return f"{tonic} {mode}"

df["norm_key_label"] = df["key_label"].apply(normalize_key)
df["norm_key_int"] = df["norm_key_label"].map(Mkey_labels)
print(df)

# Step 3: Check for missing files
missing = []

total_count = 0
for i, row in df.iterrows():
  file_path = os.path.join(REPO_ROOT, row["audio_path"])
  if not os.path.exists(file_path):
    missing.append(file_path)
  total_count += 1
print("Missing count:", len(missing), "out of", total_count)
missing[:10]

#dropping rows with missing files
df = df[~df["audio_path"].str.contains("fmak_wav_aug")]
df = df.reset_index(drop=True)
print(len(df), "available")

#!ls /content/drive/MyDrive/Colab\ Notebooks/Random\ Forest\ Model\ -\ ML\ Final/fmak_wav

# ==== STEP 4: FEATURE EXTRACTION WITH LIBROSA ====

def extract_features(file_path, sr=22050):
    """
    Extracts a set of summary features from an audio file using librosa.
    All features are numeric so they work nicely with RandomForest.
    """
    # load audio; mono=True collapses to mono, which is fine for key detection
    y, sr = librosa.load(file_path, sr=sr, mono=True)

    # Safety check: if file is empty or super short
    if len(y) == 0:
        # Return zeros for everything so code doesn't crash
        return {

        }

    # --- Timeâ€“frequency features ---
    chroma_stft = librosa.feature.chroma_stft(y=y, sr=sr)
    spec_centroid = librosa.feature.spectral_centroid(y=y, sr=sr)
    spec_bw = librosa.feature.spectral_bandwidth(y=y, sr=sr)
    rolloff = librosa.feature.spectral_rolloff(y=y, sr=sr)
    zcr = librosa.feature.zero_crossing_rate(y)

    # --- MFCCs (classic for audio tasks) ---
    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)

    features = {
        "chroma_stft_mean": np.mean(chroma_stft),
        "spectral_centroid_mean": np.mean(spec_centroid),
        "spectral_bandwidth_mean": np.mean(spec_bw),
        "rolloff_mean": np.mean(rolloff),
        "zcr_mean": np.mean(zcr),
    }

    # Add mean of each MFCC coefficient
    for i in range(mfcc.shape[0]):
        features[f"mfcc_{i+1}_mean"] = np.mean(mfcc[i])

    return features


FEATURES_CSV = os.path.join(REPO_ROOT,"audio_features", "audio_features_with_labels_plus_tonnetz_cqt.csv")


if os.path.exists(FEATURES_CSV):
    print(" Found cached features CSV. Loading:", FEATURES_CSV)
    feat_df = pd.read_csv(FEATURES_CSV)
    print("Loaded saved features:", feat_df.shape)
    feat_df.head()
else:
    # Quick dataset presence check (fail fast if audio isn't present)
    first_path = os.path.join(REPO_ROOT, df.iloc[0]["audio_path"])
    if not os.path.exists(first_path):
        raise SystemExit(
            "Dataset audio files not found locally.\n"
            "This script expects the full dataset paths like fmak_wav/... to exist.\n"
            "Either download/mount the dataset, or run training in Colab.\n"
            "Prediction still works using predict.py + rf_key_classifier.joblib."
        )

    print(" Cached features CSV not found. Computing features from audio...")

    feature_rows = []
    for i, row in tqdm(df.iterrows(), total=len(df)):
        file_path = os.path.join(REPO_ROOT, row["audio_path"])
        feats = extract_features(file_path)

        # If feature extraction failed, skip file
        if not feats:
            continue

        feats["label_int"] = row["norm_key_int"]
        feats["label_str"] = row["norm_key_label"]
        feature_rows.append(feats)

    feat_df = pd.DataFrame(feature_rows)
    print("Feature dataframe shape:", feat_df.shape)

    feat_df.to_csv(FEATURES_CSV, index=False)
    print(" Saved features to:", FEATURES_CSV)

'''
OPTIONAL:
if csv alreeady exists you can comment out this feature extraxtion method.

------------------------------------------------------------------
from tqdm import tqdm....
....
# From here on, use combined_df as your working feature dataframe
feat_df = combined_df
------------------------------------------------------------------

Otherwise uncomment this block.

------------------------------------------------------------------

from tqdm import tqdm

def extract_new_features(file_path, sr=22050):
    """
    Compute ONLY Tonnetz + Chroma CQT features.
    We do NOT recompute MFCC/spectral because we already have them saved.
    """
    y, sr = librosa.load(file_path, sr=sr, mono=True, duration=25)

    if len(y) == 0:
        return {
            "tonnetz_1_mean": np.nan,
            "tonnetz_2_mean": np.nan,
            "tonnetz_3_mean": np.nan,
            "tonnetz_4_mean": np.nan,
            "tonnetz_5_mean": np.nan,
            "tonnetz_6_mean": np.nan,
            "chroma_cqt_mean": np.nan,
            "chroma_cqt_std": np.nan,
        }

    feats = {}

    # Tonnetz
    try:
        ton = librosa.feature.tonnetz(y=y, sr=sr)
        ton_means = ton.mean(axis=1)
        for i in range(6):
            feats[f"tonnetz_{i+1}_mean"] = ton_means[i]
    except:
        for i in range(6):
            feats[f"tonnetz_{i+1}_mean"] = np.nan

    # Chroma CQT
    chroma_cqt = librosa.feature.chroma_cqt(y=y, sr=sr)
    feats["chroma_cqt_mean"] = float(np.mean(chroma_cqt))
    feats["chroma_cqt_std"] = float(np.std(chroma_cqt))

    return feats



# Compute ONLY the new features (tonnetz + chroma_cqt) for each file
new_feature_rows = []

for i, row in tqdm(df.iterrows(), total=len(df)):
    file_path = os.path.join(REPO_ROOT, row["audio_path"])
    new_feats = extract_new_features(file_path)
    new_feature_rows.append(new_feats)

#new_feats_df = pd.DataFrame(new_feature_rows)
print("New features shape:", new_feats_df.shape)
print(new_feats_df.head())

# Sanity check: row counts should match
print("Original feat_df rows:", feat_df.shape[0])
print("New feats rows:", new_feats_df.shape[0])

# Combine old + new features side by side
combined_df = pd.concat([feat_df, new_feats_df], axis=1)
print("Combined features shape:", combined_df.shape)
combined_df.head()

# Save to a NEW CSV so you keep the original too
UPDATED_FEATURES_CSV = os.path.join(
    REPO_ROOT, "audio_features_with_labels_plus_tonnetz_cqt.csv"
)
combined_df.to_csv(UPDATED_FEATURES_CSV, index=False)

print("Saved updated features to:", UPDATED_FEATURES_CSV)

# From here on, use combined_df as your working feature dataframe
feat_df = combined_df

'''

feat_df["binary_label"] = feat_df["label_str"].apply(
    lambda x: "major" if "major" in x else "minor"
)

# === LOAD PREVIOUSLY SAVED FEATURES INSTEAD OF RECOMPUTING ===

#FEATURES_CSV = os.path.join(REPO_ROOT, "audio_features_with_labels_plus_tonnetz_cqt.csv")
#feat_df = pd.read_csv(FEATURES_CSV)

#print("Loaded features:", feat_df.shape)
#print(feat_df.head())

FEATURES_CSV = os.path.join(REPO_ROOT, "audio_features", "audio_features_with_labels_plus_tonnetz_cqt.csv")
feat_df = pd.read_csv(FEATURES_CSV)


from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix
from imblearn.over_sampling import RandomOverSampler

# Drop any rows with NaNs from the new features (just in case)
feat_df = feat_df.dropna().reset_index(drop=True)

# Separate features and labels
X = feat_df.drop(columns=["label_int", "label_str", "binary_label"])
y = feat_df["binary_label"]

print("X shape:", X.shape)
print("y shape:", y.shape)

# Train/validation split (same as before)
X_train, X_val, y_train, y_val = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

print("Class counts in y_train (before oversampling):")
print(y_train.value_counts().sort_index())

# ==== OVERSAMPLING ON TRAIN ONLY ====
ros = RandomOverSampler(random_state=42)
X_train_res, y_train_res = ros.fit_resample(X_train, y_train)

print("\nClass counts in y_train_res (after oversampling):")
print(y_train_res.value_counts().sort_index())

# Random Forest model
rf_balanced = RandomForestClassifier(
    n_estimators=500,
    max_depth=None,
    max_features = "sqrt",
    random_state=42,
    n_jobs=-1
)

rf_balanced.fit(X_train_res, y_train_res)

# Evaluation on validation set (unchanged, still imbalanced & realistic)
y_val_pred = rf_balanced.predict(X_val)

print("\nClassification Report (validation, after oversampling):")
print(classification_report(y_val, y_val_pred, zero_division=0))

print("Confusion matrix (validation, after oversampling, with tonnetz + cqt):")
cm = confusion_matrix(y_val, y_val_pred)
print(cm)

import matplotlib.pyplot as plt
from sklearn.metrics import ConfusionMatrixDisplay

disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=rf_balanced.classes_)
fig, ax = plt.subplots(figsize=(4, 4))
disp.plot(ax=ax, values_format="d")
plt.title("Major/Minor Confusion Matrix (Random Forest + Tonnetz + Chroma CQT)")
plt.tight_layout()
plt.show()

import joblib
MODEL_PATH = os.path.join(REPO_ROOT, "rf_key_classifier.joblib")
FEATURES_CSV = os.path.join(REPO_ROOT, "audio_features_with_labels.csv")

joblib.dump(rf_balanced, MODEL_PATH)
feat_df.to_csv(FEATURES_CSV, index=False)

print("Saved model to:", MODEL_PATH)
print("Saved features to:", FEATURES_CSV)